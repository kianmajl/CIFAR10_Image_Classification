{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import (\n",
    "    resnet34,\n",
    "    ResNet34_Weights,\n",
    "    resnet18,\n",
    "    ResNet18_Weights,\n",
    "    vgg11,\n",
    "    VGG11_Weights,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sb\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Set seaborn theme\n",
    "sb.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and use it if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a series of transformations to apply to an image.\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=256),  # Resize the image to 256x256 pixels.\n",
    "        transforms.CenterCrop(\n",
    "            size=224\n",
    "        ),  # Crop the center of the image to 224x224 pixels.\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor.\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        ),  # Normalize the image with mean and standard deviation.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = datasets.CIFAR10(\"data\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Load the test data\n",
    "test_data = datasets.CIFAR10(\"data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation subsets\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "    train_data, [0.85, 0.15], generator=torch.Generator().manual_seed(1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense (Fully Connected) Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_neurons = n_neurons\n",
    "\n",
    "        # Initialize the weights with random values based on normal distribution with He heuristic\n",
    "        self.weights = (\n",
    "            torch.randn(n_inputs, n_neurons) * torch.sqrt(torch.tensor(2.0 / n_inputs))\n",
    "        ).to(device)\n",
    "        # Initialize the biases with zeros\n",
    "        self.biases = torch.zeros(1, n_neurons).to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = torch.matmul(self.inputs, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, b_input):\n",
    "        self.weights_gradient = torch.matmul(self.inputs.T, b_input)\n",
    "        self.biases_gradient = torch.sum(b_input, dim=0, keepdims=True)\n",
    "        self.inputs_gradient = torch.matmul(b_input, self.weights.T)\n",
    "\n",
    "        self.b_output = self.inputs_gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __repr__(self):\n",
    "        return \"ReLU\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the output using the ReLU activation function\n",
    "        self.output = torch.maximum(torch.zeros(inputs.size()).to(device), inputs)\n",
    "\n",
    "    def backward(self, b_input):\n",
    "        inputs_gradient = b_input.clone()\n",
    "        # Set the gradient to zero where the output is less than or equal to zero\n",
    "        inputs_gradient[self.output <= 0] = 0\n",
    "        self.b_output = inputs_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __repr__(self):\n",
    "        return \"Sigmoid\"\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the sigmoid function of the input tensor\n",
    "        self.output = 1 / (1 + torch.exp(-inputs))\n",
    "\n",
    "    def backward(self, b_input):\n",
    "        inputs_gradient = b_input * (1 - self.output) * self.output\n",
    "        self.b_output = inputs_gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categorical_Cross_Entropy_loss_Softmax:\n",
    "    def forward(self, inputs, batch_size, class_label=None):\n",
    "        max_out, max_inds = torch.max(inputs, dim=1, keepdims=True)\n",
    "\n",
    "        # Calculate the exponential values\n",
    "        exp_vals = torch.exp(inputs - max_out)\n",
    "\n",
    "        # Calculate the softmax values\n",
    "        self.softmax = exp_vals / torch.sum(exp_vals, dim=1, keepdims=True)\n",
    "        self.softmax += 1e-7  # Add a small value to avoid division by zero\n",
    "\n",
    "        # Calculate the loss\n",
    "        if class_label is not None:\n",
    "            self.class_label = class_label\n",
    "            self.batch_size = batch_size\n",
    "            self.loss = -torch.sum(self.class_label * torch.log(self.softmax))\n",
    "\n",
    "    def backward(self):\n",
    "        # Calculate the gradient of the inputs\n",
    "        self.b_output = (self.softmax - self.class_label) / self.batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update(self, layer):\n",
    "        layer.weights -= (\n",
    "            self.learning_rate * layer.weights_gradient\n",
    "        )  # Update the weights\n",
    "        layer.biases -= self.learning_rate * layer.biases_gradient  # Update the biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34:\n",
    "    def __init__(self):\n",
    "        # Load the ResNet34 model with default weights\n",
    "        self.resnet34 = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        modules = list(self.resnet34.children())[:-1]\n",
    "\n",
    "        # Create a new model with all the layers except the last one\n",
    "        self.resnet34 = torch.nn.Sequential(*modules)\n",
    "\n",
    "        self.resnet34.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        self.resnet34 = self.resnet34.to(device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"ResNet34\"\n",
    "\n",
    "    def get_features(self, images):\n",
    "        with torch.no_grad():\n",
    "            # Get the features from the features extractor model\n",
    "            features = self.resnet34(images)\n",
    "        return features\n",
    "\n",
    "    def get_size(self):\n",
    "        with torch.no_grad():\n",
    "            features = torch.flatten(\n",
    "                self.resnet34(torch.zeros(1, 3, 224, 224).to(device)), start_dim=1\n",
    "            )\n",
    "        # Return the size of the features\n",
    "        return features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18:\n",
    "    def __init__(self):\n",
    "        # Load the ResNet18 model with default weights\n",
    "        self.resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        modules = list(self.resnet18.children())[:-1]\n",
    "\n",
    "        # Create a new model with all the layers except the last one\n",
    "        self.resnet18 = torch.nn.Sequential(*modules)\n",
    "\n",
    "        self.resnet18.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        self.resnet18 = self.resnet18.to(device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"ResNet18\"\n",
    "\n",
    "    def get_features(self, images):\n",
    "        with torch.no_grad():\n",
    "            # Get the features from the features extractor model\n",
    "            features = self.resnet18(images)\n",
    "        return features\n",
    "\n",
    "    def get_size(self):\n",
    "        with torch.no_grad():\n",
    "            features = torch.flatten(\n",
    "                self.resnet18(torch.zeros(1, 3, 224, 224).to(device)), start_dim=1\n",
    "            )\n",
    "        # Return the size of the features\n",
    "        return features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11:\n",
    "    def __init__(self):\n",
    "        # Load the VGG11 model with default weights\n",
    "        self.vgg11 = vgg11(weights=VGG11_Weights.DEFAULT)\n",
    "        modules = list(self.vgg11.children())[:-1]\n",
    "\n",
    "        # Create a new model with all the layers except the last one\n",
    "        self.vgg11 = torch.nn.Sequential(*modules)\n",
    "\n",
    "        self.vgg11.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        self.vgg11 = self.vgg11.to(device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"VGG11\"\n",
    "\n",
    "    def get_features(self, images):\n",
    "        with torch.no_grad():\n",
    "            # Get the features from the features extractor model\n",
    "            features = self.vgg11(images)\n",
    "        return features\n",
    "\n",
    "    def get_size(self):\n",
    "        with torch.no_grad():\n",
    "            features = torch.flatten(\n",
    "                self.vgg11(torch.zeros(1, 3, 224, 224).to(device)), start_dim=1\n",
    "            )\n",
    "        # Return the size of the features\n",
    "        return features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_resnet18 = ResNet18()\n",
    "fe_resnet34 = ResNet34()\n",
    "fe_vgg11 = VGG11()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_extractor=fe_resnet34,\n",
    "        number_of_classes=10,\n",
    "        batch_size=32,\n",
    "        tune=False,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.number_of_classes = number_of_classes\n",
    "\n",
    "        self.optimizer = SGD(learning_rate=0.001)\n",
    "        self.features_extractor = features_extractor\n",
    "        self.n_inputs = self.features_extractor.get_size()[1]\n",
    "\n",
    "        if not tune:\n",
    "            self.layers = [Dense(self.n_inputs, 20), Dense(20, self.number_of_classes)]\n",
    "            self.activations = [ReLU(), Categorical_Cross_Entropy_loss_Softmax()]\n",
    "\n",
    "        # Create a data loader for the training data\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            dataset=train_subset, shuffle=True, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "        # Create a data loader for the validation data\n",
    "        self.val_loader = torch.utils.data.DataLoader(\n",
    "            dataset=val_subset, shuffle=False, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "        # Create a data loader for the test data\n",
    "        self.test_loader = torch.utils.data.DataLoader(\n",
    "            dataset=test_data, shuffle=False, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def _forward_propagation(self, data, y_1hot=None):\n",
    "        \"\"\"\n",
    "        This function performs forward propagation on a neural network.\n",
    "        It takes as input a data tensor and an one-hot encoded label tensor.\n",
    "        \"\"\"\n",
    "        if len(self.activations) != len(self.layers):\n",
    "            raise Exception(\n",
    "                \"The number of activations should be equal to the number of layers\"\n",
    "            )\n",
    "\n",
    "        inputs = torch.flatten(self.features_extractor.get_features(data), start_dim=1)\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            layer.forward(inputs)\n",
    "            if activation == self.activations[-1]:\n",
    "                activation.forward(layer.output, self.batch_size, y_1hot)\n",
    "                break\n",
    "            else:\n",
    "                activation.forward(layer.output)\n",
    "            inputs = activation.output\n",
    "\n",
    "    def _test_val(self):\n",
    "        acc_hist = []\n",
    "        loss_hist = []\n",
    "        for data, label in self.val_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            y_1hot = torch.nn.functional.one_hot(\n",
    "                label, num_classes=self.number_of_classes\n",
    "            )\n",
    "\n",
    "            self._forward_propagation(data, y_1hot)\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            y_predict = torch.argmax(self.activations[-1].softmax, dim=1)\n",
    "            accuracy = torch.mean((torch.argmax(y_1hot, dim=1) == y_predict).float())\n",
    "            acc_hist.append(accuracy)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = self.activations[-1].loss\n",
    "            loss_hist.append(loss)\n",
    "\n",
    "        return torch.mean(torch.Tensor(loss_hist)), torch.mean(torch.Tensor(acc_hist))\n",
    "\n",
    "    def evaluate(self, train=False):\n",
    "        if train:\n",
    "            y_true = []\n",
    "            y_predict = []\n",
    "\n",
    "            for data, label in self.train_loader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                y_1hot = torch.nn.functional.one_hot(\n",
    "                    label, num_classes=self.number_of_classes\n",
    "                )\n",
    "\n",
    "                self._forward_propagation(data, y_1hot)\n",
    "\n",
    "                y_pred = torch.argmax(self.activations[-1].softmax, dim=1)\n",
    "\n",
    "                for yt, yp in zip(torch.argmax(y_1hot, dim=1), y_pred):\n",
    "                    y_true.append(yt.item())\n",
    "                    y_predict.append(yp.item())\n",
    "\n",
    "            return (\n",
    "                accuracy_score(y_true, y_predict),\n",
    "                f1_score(y_true, y_predict, average=\"weighted\"),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            y_true = []\n",
    "            y_predict = []\n",
    "\n",
    "            for data, label in self.test_loader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                y_1hot = torch.nn.functional.one_hot(\n",
    "                    label, num_classes=self.number_of_classes\n",
    "                )\n",
    "\n",
    "                self._forward_propagation(data, y_1hot)\n",
    "\n",
    "                y_pred = torch.argmax(self.activations[-1].softmax, dim=1)\n",
    "\n",
    "                for yt, yp in zip(torch.argmax(y_1hot, dim=1), y_pred):\n",
    "                    y_true.append(yt.item())\n",
    "                    y_predict.append(yp.item())\n",
    "\n",
    "            return (\n",
    "                accuracy_score(y_true, y_predict),\n",
    "                f1_score(y_true, y_predict, average=\"weighted\"),\n",
    "            )\n",
    "\n",
    "    def predict(self, data):\n",
    "        data = data.to(device)\n",
    "\n",
    "        self._forward_propagation(data)\n",
    "\n",
    "        y_predict = torch.argmax(self.activations[-1].softmax, dim=1)\n",
    "        return y_predict\n",
    "    \n",
    "    def train(self, epochs=20, disable_tqdm=False):\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.train_loss_history = []\n",
    "        self.val_loss_history = []\n",
    "\n",
    "        self.train_acc_history = []\n",
    "        self.val_acc_history = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            with tqdm(self.train_loader, unit=\"batch\", disable=disable_tqdm) as tepoch:\n",
    "                # Initialize the history lists for each epoch\n",
    "                acc_hist = []\n",
    "                loss_hist = []\n",
    "                for data, label in tepoch:\n",
    "                    tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "                    # Transfer the data to the GPU\n",
    "                    data = data.to(device)\n",
    "                    label = label.to(device)\n",
    "\n",
    "                    # Convert the labels to one-hot encoded vectors\n",
    "                    y_1hot = torch.nn.functional.one_hot(\n",
    "                        label, num_classes=self.number_of_classes\n",
    "                    )\n",
    "\n",
    "                    self._forward_propagation(data, y_1hot)\n",
    "\n",
    "                    # Calculate the accuracy\n",
    "                    y_predict = torch.argmax(self.activations[-1].softmax, dim=1)\n",
    "                    accuracy = torch.mean(\n",
    "                        (torch.argmax(y_1hot, dim=1) == y_predict).float()\n",
    "                    )\n",
    "                    acc_hist.append(accuracy)\n",
    "\n",
    "                    # Calculate the loss\n",
    "                    loss = self.activations[-1].loss\n",
    "                    loss_hist.append(loss)\n",
    "\n",
    "                    # Backward propagation\n",
    "                    self.activations[-1].backward()\n",
    "                    b_input = self.activations[-1].b_output\n",
    "                    for layer, activation in zip(\n",
    "                        reversed(self.layers), reversed(self.activations[:-1])\n",
    "                    ):\n",
    "                        layer.backward(b_input)\n",
    "                        activation.backward(layer.b_output)\n",
    "                        b_input = activation.b_output\n",
    "                    self.layers[0].backward(b_input)\n",
    "\n",
    "                    # Update the weights and biases\n",
    "                    for layer in self.layers:\n",
    "                        self.optimizer.update(layer)\n",
    "\n",
    "                    tepoch.set_postfix(\n",
    "                        loss=loss.item(), accuracy=f\"{accuracy.item()*100:.2f}%\"\n",
    "                    )\n",
    "\n",
    "            # Calculate the validation loss and accuracy\n",
    "            val_loss, val_acc = self._test_val()\n",
    "\n",
    "            # Append the history lists\n",
    "            self.train_loss_history.append(torch.mean(torch.Tensor(loss_hist)))\n",
    "            self.val_loss_history.append(val_loss)\n",
    "\n",
    "            self.train_acc_history.append(torch.mean(torch.Tensor(acc_hist)) * 100)\n",
    "            self.val_acc_history.append(val_acc * 100)\n",
    "\n",
    "            # Print the results\n",
    "            if not disable_tqdm:\n",
    "                print(f\"Epoch:{epoch+1}\")\n",
    "                print(f\"Training Loss: {self.train_loss_history[-1]}\")\n",
    "                print(f\"Validation Loss: {self.val_loss_history[-1]}\")\n",
    "                print(f\"Training Accuracy: {self.train_acc_history[-1]:.2f}%\")\n",
    "                print(f\"Validation Accuracy: {self.val_acc_history[-1]:.2f}%\")\n",
    "                print(\"--------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
